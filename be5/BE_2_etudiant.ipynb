{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiabilité et propagation d'incertitude - BE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Import des bibliothèques Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sci\n",
    "import openturns as ot\n",
    "import scipy.stats as stat\n",
    "import scipy.optimize as opt\n",
    "import time as t #utile pour mesurer le temps d'execution des fonctions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Description du problème\n",
    "## 1-1) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite étudier la fiabilité d'une passerelle soumise à un chargement réparti sur son tablier. Pour cela, la passerelle est modélisée par une poutre de longueur $L$, encastrée à son extrémité gauche et en appui simple à son extrémité droite, le chargement est noté $Q(l)$. La passerelle est de section rectangulaire de base $b$ et de hauteur $h$. Le module d'élasticité du matériau servant à la construction de la passerelle est $E$. La défaillance est caractérisée par un déplacement maximal autorisé noté $u_{max}$. \n",
    "\n",
    "La résolution de l'équation de la statique permettant de trouver le déplacement de la passerelle est effectuée par la méthode des éléments finis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2) Résolution par la méthode des éléments finis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre d'éléments est noté $n_{elem}$. On suppose que le chargement réparti est vertical et compte $n_{nodes}=n_{elem}+1$ composantes notées $Q_i,~i=1,\\cdots,n_{nodes}$. Le code suivant crée la fonction Python qui résout l'équation de la statique par la méthode des éléments finis et renvoie le déplacement max de la structure. Pour cela $n_{elem}$ éléments de poutre à 2 degrés de liberté par noeud sont utilisés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_structure(n_elem,L,E,I,Q):\n",
    "    \n",
    "        #matrice de rigidité totale\n",
    "        K = np.zeros((2*(n_elem+1),2*(n_elem+1)))\n",
    "        #Longeur des éléments\n",
    "        l = L/n_elem\n",
    "        #boucle sur les éléments\n",
    "        for i in range(n_elem):\n",
    "            #matrice élémentaire\n",
    "            K_elem = E*I/l**3*np.array([[12.0,6.0*l,-12.0,6.0*l],\\\n",
    "                                        [6.0*l,4.0*l**2,-6.0*l,2.0*l**2],\\\n",
    "                                       [-12.0,-6.0*l,12.0,-6.0*l],\\\n",
    "                                       [6*l,2.0*l**2,-6.0*l,4.0*l**2]])\n",
    "            #Assemblage\n",
    "            K[2*i:2*(i+1),2*i:2*(i+1)] = K[2*i:2*(i+1),2*i:2*(i+1)] + K_elem[0:2,0:2]\n",
    "            K[2*(i+1):2*(i+2),2*i:2*(i+1)] = K[2*(i+1):2*(i+2),2*i:2*(i+1)] + K_elem[2:4,0:2]\n",
    "            K[2*i:2*(i+1),2*(i+1):2*(i+2)] = K[2*i:2*(i+1),2*(i+1):2*(i+2)] + K_elem[0:2,2:4]\n",
    "            K[2*(i+1):2*(i+2),2*(i+1):2*(i+2)] = K[2*(i+1):2*(i+2),2*(i+1):2*(i+2)] + K_elem[2:4,2:4]\n",
    "            #conditions aux limites\n",
    "        #encastrement en l = 0\n",
    "        K[0:2,:] = 0.0\n",
    "        K[:,0:2] = 0.0\n",
    "        K[0,0] = 1.0\n",
    "        K[1,1] = 1.0\n",
    "        #appui simple en l = L\n",
    "        K[-2,:] = 0.0\n",
    "        K[:,-2] = 0.0\n",
    "        K[-2,-2] = 1.0\n",
    "        #Decomposition de Cholesky\n",
    "        K_fact = sci.linalg.cho_factor(K)\n",
    "        #Second membre\n",
    "        F = np.zeros((2*(n_elem+1),))\n",
    "        F[0:-1:2] = Q    \n",
    "        F[0:2] = 0.0\n",
    "        F[-2] = 0.0\n",
    "        #resolution du système KU = F\n",
    "        U = sci.linalg.cho_solve(K_fact,F)    \n",
    "        return U\n",
    "\n",
    "def interpolation_EF(X,U,L):\n",
    "    n_elem = len(U)/2-1\n",
    "    l = L/n_elem\n",
    "    U_X = np.zeros(X.shape)\n",
    "    i = 0\n",
    "    for x in X:\n",
    "        #on cherche à quel élément appartient x et quelle est sa position relative\n",
    "        n = np.int((x-1e-12)/l) #on se décale très légèrement sur la gauche \n",
    "        #pour ne pas avoir de problème en x=L qui donnerait n=en_elem +1 et qui poserait problème\n",
    "        s = (x-(n*l))/l\n",
    "        #On recupère U_i et U_j correspondant\n",
    "        u_i = U[2*n]\n",
    "        theta_i = U[2*n+1]\n",
    "        u_j = U[2*(n+1)]\n",
    "        theta_j = U[2*(n+1)+1]\n",
    "        u_x = u_i*(1.0-3.0*s**2+2.0*s**3)+u_j*(3.0*s**2-2.0*s**3)\\\n",
    "        +theta_i*(l*(s-2.0*s**2+s**3))+theta_j*(l*(-s**2+s**3))\n",
    "        U_X[i] = u_x\n",
    "        i = i+1   \n",
    "    return U_X    \n",
    "\n",
    "def find_max_dep(n_elem,L,E,I,Q):\n",
    "    #On commence par résoudre le problème discrétisé\n",
    "    U = u_structure(n_elem,L,E,I,Q)\n",
    "    #Puis on cherche le min du problème continu grace à la fonction d'interpolation\n",
    "    res_opt = opt.minimize(interpolation_EF,np.array([L/2.0]),method = \"SLSQP\", bounds=[[0.0,L]],args=(U,L),tol=1e-12)\n",
    "    u_max = res_opt['fun']\n",
    "    l_max = res_opt['x']\n",
    "    return l_max,u_max,U    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger \"><b> ** Dans la suite on fixera $L=10.0$, $b=1.0$, $h=0.1$, $E =12e^9$, $Q_{total} = -3000$ **</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant permet de tester le code éléments finis définis à l'aide des 3 fonctions Python ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\"> **Question 1) :** Expliquer chacune des 3 fonctions. Faire varier le nombre d'éléménts et observer l'influence sur les résultats.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_elem = 5\n",
    "n_nodes = n_elem + 1\n",
    "#Paramètres géométriques\n",
    "L = 10.0 #longueur en métre\n",
    "b = 1.0 #base de la section en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "I = b*h**3/12.0\n",
    "#Paramètre matériaux\n",
    "E = 12e9 #Module d'young en Pascal N/m^2\n",
    "#Chargement : \n",
    "#Chargement total\n",
    "Q_total = -3000.0 #Newton\n",
    "#Le chargement est réparti uniformement sur les noeuds entre les 2 extremitées\n",
    "Q_elem = Q_total/n_elem\n",
    "Q = np.ones((n_nodes,))*Q_elem\n",
    "#Résolution du problème\n",
    "t1 = t.time()\n",
    "U = u_structure(n_elem,L,E,I,Q)\n",
    "t2 = t.time()\n",
    "#Résolution + recherche du minimum\n",
    "t3 = t.time()\n",
    "l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "t4 = t.time()\n",
    "#interpolation de la solution EF pour le graphique\n",
    "X = np.linspace(0.0,L,100)\n",
    "U_X = interpolation_EF(X,U,L)\n",
    "#Représentation graphique\n",
    "mesh = np.linspace(0,L,n_elem+1)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(mesh,np.zeros(mesh.shape),'k.',label='mesh')\n",
    "ax.plot([0.0,L],[0.0,0.0],'k')\n",
    "ax.plot(mesh,U[0:-1:2],'r.',label = 'U')\n",
    "ax.plot(X,U_X,'r',label ='U_X')\n",
    "ax.plot(l_max,u_max,'bo',label='u_max')\n",
    "ax.set_xlabel('l')\n",
    "ax.set_ylabel('u')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "#Affichage des résultats\n",
    "print (\"le déplacement max est\", abs(u_max) ,\"m\")\n",
    "print (\"il est atteint en l=\",l_max, \"m\")\n",
    "print (\"la résolution du problème a duré \", (t2-t1), 's')\n",
    "print (\"la résolution du problème + problème d'optimisation a duré\", (t4-t3), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 2 :** Compléter le code suivant qui permet de tracer la courbe $u_{max} = f(n_{elem})$ pour $n_{elem}$ qui varie entre 3 et 50, quelle phénomène est illustré? En déduire le nombre minimal d'éléments à utiliser pour la simulation.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_elem = np.arange(3,50,1) \n",
    "#Paramètres géométriques\n",
    "L = 10.0 #longueur en métre\n",
    "b = 1.0 #base de la section en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "I = b*h**3/12.0\n",
    "#Paramètre matériaux\n",
    "E = 12e9 #Module d'young en Pascal N/m^2\n",
    "#Chargement : \n",
    "#Chargement total\n",
    "Q_total = -3000.0 #Newton\n",
    "#Liste pour stocker les résultats\n",
    "U_max = []\n",
    "for n_elem in N_elem:\n",
    "    n_elem = int(n_elem)\n",
    "    n_nodes = n_elem + 1\n",
    "    #Le chargement est réparti uniformement sur les noeuds entre les 2 extremitées\n",
    "    Q_elem = Q_total/n_elem\n",
    "    Q = np.ones((n_nodes,))*Q_elem\n",
    "    #Résolution du problème\n",
    "    l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "    U_max.append(u_max)  \n",
    "fig,(ax_1) = plt.subplots(1,1,figsize=(20,5))\n",
    "ax_1.plot(N_elem,U_max,'k.',label=r'$u_{max}$')\n",
    "ax_1.set_xlabel(r'$n_{elem}$')\n",
    "ax_1.set_ylabel(r'$u_{max}$')\n",
    "ax_1.legend(loc=0)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Propagation d'incertitude et fiabilité\n",
    "\n",
    "On suppose à présent que les varibales $b$ et $E$ sont aléatoires. L'objectif est de modéliser ces variables incertaines et de résoudre un problème de fiabilité par les méthode de Monte Carlo, FORM et tirage d'importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1) Modèle probabiliste des variables $b$ et $E$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la suite on suppose que le code EF ci dessus donne la **valeur exacte** du déplacement maximal de la passerelle.\n",
    "Dans cet exercice nous allons considérer que les paramètres $E$ et $b$ sont des variables aléatoires indépendantes telles que :\n",
    "- $E$ suit une loi log-normale de moyenne $\\mu_E=12e9$ et de coefficient de variation $10\\%$ http://openturns.github.io/openturns/latest/user_manual/_generated/openturns.LogNormal.html?highlight=lognormal. Remarque : $X$ de loi log-normale, $\\mu_X= E[X]$, $\\sigma_X=\\sqrt{Var[X]}$, il existe une unique variable $Y$ de loi normale telle que $ln(X) = Y$ de moyenne $\\mu_Y=\\lambda_X$ et d'ecart type $\\sigma_Y=\\xi_X$ et nous avons\n",
    "$$\n",
    "\\lambda_X = ln\\left( \\frac{\\mu_X}{\\sqrt{1+(\\frac{\\sigma_X}{\\mu_X})^2}}\\right)\n",
    "$$\n",
    "$$\n",
    "\\xi_X = \\sqrt{ ln(1+(\\frac{\\sigma_X}{\\mu_X})^2)}\n",
    "$$\n",
    "\n",
    "- $b$ suit une loi uniforme sur $[0.9,1.1]$ http://openturns.github.io/openturns/latest/user_manual/_generated/openturns.Uniform.html?highlight=uniform\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\"> **Question 2) :** Compléter le code ci dessous afin de définir le modèle probabiliste des variables $E$ et $b$.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_E = 12e9\n",
    "cv_E = 0.1\n",
    "Lambda_E = np.log(mean_E/(np.sqrt(1.+cv_E**2)))\n",
    "Xi_E = np.sqrt(np.log(1.+cv_E**2))\n",
    "Loi_E = ot.LogNormal(Lambda_E,Xi_E)\n",
    "print (\"mu_E =\",Loi_E.getMean()[0],\", cv_E=\", Loi_E.getStandardDeviation()[0]/Loi_E.getMean()[0])\n",
    "b_inf = 0.9\n",
    "b_sup = 1.1\n",
    "Loi_b = ot.Uniform(0.9,1.1)\n",
    "print (\"mu_b=\",Loi_b.getMean()[0],\", cv_b=\", Loi_b.getStandardDeviation()[0]/Loi_b.getMean()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois la loi de probabilité des paramètres aléatoires créée, nous allons générer des échantillons suivant cette loi de probabilité. Le code suivant génère 3 échantillons, exécute le code éléments finis et trace les résultats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##génération d'échantillons\n",
    "Echantillon_E = np.array(Loi_E.getSample(3))\n",
    "Echantillon_b = np.array(Loi_b.getSample(3))\n",
    "##paramètres\n",
    "L = 10.0 #longueur en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "#Chargement : \n",
    "#Chargement total\n",
    "Q_total = -3000.0 #Newton\n",
    "#Le chargement est réparti uniformement sur les noeuds entre les 2 extremitées\n",
    "n_elem = 50\n",
    "n_nodes = n_elem+1\n",
    "Q_elem = Q_total/n_elem\n",
    "Q = np.ones((n_nodes,))*Q_elem\n",
    "##Exécution du code EF pour chaque échantillon\n",
    "for i in range(3):\n",
    "    E = Echantillon_E[i]\n",
    "    b = Echantillon_b[i]\n",
    "    I = b*h**3/12.0\n",
    "    l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "    #interpolation de la solution EF\n",
    "    X = np.linspace(0.0,L,100)\n",
    "    U_X = interpolation_EF(X,U,L)\n",
    "    #Représentation graphique\n",
    "    mesh = np.linspace(0,L,n_elem+1)\n",
    "    fig,(ax_2) = plt.subplots(1,1,figsize=(20,5))\n",
    "    #ax_1.plot(mesh,Q,'r.',label=\"Q\")\n",
    "    #ax_1.plot(mesh,Q,'r')\n",
    "    #ax_1.set_xlabel('l')\n",
    "    #ax_1.set_ylabel('Q')\n",
    "    #ax_1.legend(loc=0)\n",
    "    ax_2.plot(mesh,np.zeros(mesh.shape),'k.',label='mesh')\n",
    "    ax_2.plot([0.0,L],[0.0,0.0],'k')\n",
    "    ax_2.plot(mesh,U[0:-1:2],'r.',label = 'U')\n",
    "    ax_2.plot(X,U_X,'r',label ='U_X')\n",
    "    ax_2.plot(l_max,u_max,'bo',label=r'$u_{max}')\n",
    "    ax_2.set_xlabel('l')\n",
    "    ax_2.set_ylabel('u')\n",
    "    ax_2.set_title(r'$u_{max}=$'+str(u_max))\n",
    "    ax_2.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 3) : ** En vous inspirant du code précédent compléter le code suivant afin de générer un échantillon de taille 500 de la valeur $u_{max}$ et tracer l'histogramme correspondant.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##génération d'échantillons\n",
    "n_sim = 500\n",
    "Echantillon_E = np.array(Loi_E.getSample(n_sim))\n",
    "Echantillon_b = np.array(Loi_b.getSample(n_sim))\n",
    "##paramètres\n",
    "L = 10.0 #longueur en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "#Chargement : \n",
    "#Chargement total\n",
    "Q_total = -3000.0 #Newton\n",
    "#Le chargement est réparti uniformement sur les noeuds entre les 2 extremitées\n",
    "n_elem = 50\n",
    "n_nodes = n_elem+1\n",
    "Q_elem = Q_total/n_elem\n",
    "Q = np.ones((n_nodes,))*Q_elem\n",
    "#Vecteur U_max\n",
    "U_max = np.zeros((n_sim,))\n",
    "##Exécution du code EF pour chaque échantillon\n",
    "for i in range(n_sim):\n",
    "    E = Echantillon_E[i]\n",
    "    b = Echantillon_b[i]\n",
    "    I = b*h**3/12.0\n",
    "    l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "    U_max[i] = u_max\n",
    "fig,(ax_2) = plt.subplots(1,1,figsize=(10,10))\n",
    "ax_2.hist(U_max,15,density=True)\n",
    "ax_2.set_xlabel('u_max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2) Fiabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1) Introduction\n",
    "La fonction de performance est définie par : \n",
    "$$\n",
    "G(X) = d_{seuil}-|u_{max}(X)|\n",
    "$$\n",
    "on fixera $d_{seuil}=0.022$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 4) : ** Compléter le code suivant afin d'implémenter la fonction de performance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  G(X):\n",
    "    d_seuil = 0.022\n",
    "    E = X[0]\n",
    "    b = X[1]\n",
    "    #définition des paramètres \n",
    "    I = b*h**3/12.\n",
    "    #Détermination de u_max\n",
    "    l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "    return d_seuil-abs(u_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2) Transformation iso-probabiliste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 5) :** Compléter les deux fonctions ci-dessous permettant de passer de l'espace physique à l'espace normal standard et inversement.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = ot.Normal()\n",
    "def T_iso_proba(X):\n",
    "    u_1 = N.computeQuantile(Loi_E.computeCDF(X[0]))\n",
    "    u_2 = N.computeQuantile(Loi_b.computeCDF(X[1]))\n",
    "    return np.array([u_1,u_2])\n",
    "def inv_T_iso_proba(U):\n",
    "    E = Loi_E.computeQuantile(N.computeCDF(U[0]))\n",
    "    b = Loi_b.computeQuantile(N.computeCDF(U[1]))\n",
    "    return np.array([E, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3) First Order Reliability method\n",
    "On rappelle que la mise en oeuvre de la méthode FORM passe par la résolution du problème d'optimisation sous contrainte, \n",
    "$$\n",
    "\\min_{u} \\sqrt{uu^T}\n",
    "$$\n",
    "sous la contrainte $H(u)\\leqslant 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 6) :** Compléter le code suivant afin de créer la fonction objective et la contrainte du problème d'optimisation. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_obj(U):\n",
    "    y = np.sqrt(np.sum(U**2))\n",
    "    return y\n",
    "def H(U):\n",
    "    X = inv_T_iso_proba(U)\n",
    "    return -G(X)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent résoudre ce problème d'optimisation à l'aide de la bibliothèque d'optimisation scipy.optimize https://docs.scipy.org/doc/scipy/reference/optimize.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 7) : ** En vous aidant de la documentation de la fonction minimize de scipy, utiliser la méthode d'optimisation 'COBYLA' pour résoudre le problème précédent. (Attention au signe de la contrainte)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint ={'type':'ineq','fun':H}\n",
    "x_0 = [0.,0.]\n",
    "sol_opt = opt.minimize(f_obj,x_0,method = 'COBYLA', constraints = constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">**Question 8) : **Compléter le code suivant afin de déterminer :\n",
    "**la valeur de l'indice de fiabilité d'Hasofer et Lind**,\n",
    "**l'approximation de la probabilité de défaillance par la méthode FORM**, \n",
    "**le nombre de résolution éléments finis effectuées**.\n",
    "\n",
    "\n",
    "Que pouvez vous dire du coût numérique de cette approche? Quel nombre (approximatif) de simulations serait nécessaire pour estimer cette probabilité par la méthode de Monte-Carlo?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (sol_opt)\n",
    "u_star = sol_opt['x']\n",
    "beta = sol_opt['fun']\n",
    "n_eval = sol_opt['nfev']\n",
    "P_f_FORM = N.computeCDF(-beta)\n",
    "print (\"Coordonnés de P_star =\", u_star)\n",
    "print (\"Indice d'Hasofer Lind=\", beta)\n",
    "print (\"P_f_FORM=\", P_f_FORM)\n",
    "print (\"Le simulateur a été utilisé \",n_eval, \"fois\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On souhaite vérifier la forme de l'état limite $H(u_1,u_2)=0$, dans le plan $(u_1,u_2)$ au voisinage de $P^\\star$. Pour cela il faut déterminer les points $(u_1,u_2)$ tels que $H(u_1,u_2)=0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 9) : **Le problème précédent est sous déterminé. Proposez une méthode afin de trouver un nombre $n$ de solutions différentes au voisinage de $P^\\star$. Implémenter cette méthode et tracer  l'état limite dans l'espace normal standard. L'hypothèse faite à la question précédente est elle vérifiée?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_obj(u_2,u_1):\n",
    "    X = inv_T_iso_proba(np.array([u_1,u_2]))\n",
    "    return abs(G(X))   \n",
    "n = 10\n",
    "u_1_star = u_star[0]\n",
    "u_2_star = u_star[1]\n",
    "delta_u_1 = 0.03\n",
    "u_sol_p = []\n",
    "h_sol_p = []\n",
    "u_sol_m = []\n",
    "h_sol_m = []\n",
    "for i in range(n):\n",
    "    u_1 = u_1_star+delta_u_1\n",
    "    sol_opt = opt.minimize(f_obj,u_2_star,method = 'COBYLA',args=(u_1))\n",
    "    u_2_star = sol_opt['x']\n",
    "    u_sol_p.append([u_1,u_2_star])\n",
    "    h_sol_p.append(sol_opt['fun'])\n",
    "    u_1_star = u_1\n",
    "\n",
    "u_1_star = u_star[0]\n",
    "u_2_star = u_star[1]\n",
    "for i in range(n):\n",
    "    u_1 = u_1_star-delta_u_1\n",
    "    sol_opt = opt.minimize(f_obj,u_2_star,method = 'COBYLA',args=(u_1))\n",
    "    u_2_star = sol_opt['x']\n",
    "    u_sol_m.append([u_1,u_2_star])\n",
    "    h_sol_m.append(sol_opt['fun'])\n",
    "    u_1_star = u_1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_1_star = u_star[0]\n",
    "u_2_star = u_star[1]\n",
    "u_sol_p = np.array(u_sol_p)\n",
    "u_sol_m = np.array(u_sol_m)\n",
    "plt.figure()\n",
    "plt.plot(u_sol_p[:,0],u_sol_p[:,1],'+')\n",
    "plt.plot(u_sol_m[:,0],u_sol_m[:,1],'+')\n",
    "plt.plot(u_1_star,u_2_star,'+',label = 'P_star')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Dimensionnement fiabiliste \n",
    "On souhaite maintenant optimiser la passerelle de sorte qu'elle soit de masse minimale sous la contrainte de fiabilité $P_f\\leq 1e-6$. Pour cela on optimisera sur les variables géométriques $b$ et $h$ du problème. La variable $b$ étant une variable aléatoire nous optimiserons sa moyenne $\\mu_B$ en supposant que la variable suit toujours une loi uniforme sur $[\\mu_B-0.1,\\mu_B+0.1]$.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 9bis) : **Ecrire la formulation du problème d'optimisation</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 10) : **Compléter le code ci-dessous afin d'implémenter la fonction objectif du problème d'optimisation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_obj_opt(X):\n",
    "    mu_B =  #A compléter\n",
    "    h =  #A compléter\n",
    "    return  #A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 11) : **Le calcul de la contrainte fait intervenir le calcul de la probabilité de défaillance que nous estimons par la méthode FORM. Compléter le code suivant afin d'implémenter le calcul de $P_f^{FORM}$ </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrainte_fiab(X):\n",
    "    #modèle probabiliste des variables d'entrée (la loi de E reste inchangée)\n",
    "    mu_B =  #A compléter\n",
    "    b_inf =  #A compléter\n",
    "    b_sup =  #A compléter\n",
    "    Loi_b = ot.Uniform(b_inf,b_sup)\n",
    "    #tranformation iso_proba\n",
    "    N = ot.Normal()\n",
    "    \n",
    "    def inv_T_iso_proba(U):\n",
    "        E = Loi_E.computeQuantile(N.computeCDF(U[0]))\n",
    "        b = #A compléter\n",
    "        return np.array([E, b])\n",
    "    \n",
    "    def T_iso_proba(Y): #Y[0] = E, Y[1] = B\n",
    "        u_1 = N.computeQuantile(Loi_E.computeCDF(Y[0]))\n",
    "        u_2 = #A compléter\n",
    "        return np.array([u_1,u_2])\n",
    "    \n",
    "    #FORM\n",
    "    def  G(Y):\n",
    "        d_seuil = 0.022\n",
    "        ##paramètres\n",
    "        L = 10.0 #longueur en métre\n",
    "        h = #A compléter #hauteur de la section en métre\n",
    "        #Chargement : \n",
    "        #Chargement total\n",
    "        Q_total = -3000.0 #Newton\n",
    "        #Le chargement est réparti uniformement sur les noeuds entre les 2 extremitées\n",
    "        n_elem = 50\n",
    "        n_nodes = n_elem+1\n",
    "        Q_elem = Q_total/n_elem\n",
    "        Q = np.ones((n_nodes,))*Q_elem\n",
    "        E = Y[0]\n",
    "        b = Y[1]\n",
    "        #définition des paramètres \n",
    "        I = b*h**3/12.\n",
    "        #Détermination de u_max\n",
    "        l_max,u_max,U = find_max_dep(n_elem,L,E,I,Q)\n",
    "        return d_seuil-abs(u_max)\n",
    "\n",
    "    def f_obj_FORM(U):\n",
    "        y = np.sqrt(np.sum(U**2))\n",
    "        return y\n",
    "    \n",
    "    def H(U):\n",
    "        Y = inv_T_iso_proba(U)\n",
    "        return -G(Y) \n",
    "    \n",
    "    constraint ={'type':'ineq','fun':H}\n",
    "    x_0 = [0.,0.]\n",
    "    sol_opt = opt.minimize(#A compléter ,x_0,method = 'COBYLA', constraints = constraint) \n",
    "    u_star = sol_opt['x']\n",
    "    beta = sol_opt['fun']\n",
    "    n_eval = sol_opt['nfev']\n",
    "    P_f_FORM = N.computeCDF(-beta)\n",
    "    return  #A compléter\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier l'implémentation de la contrainte au point étudié précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1.,0.1])\n",
    "print (-contrainte_fiab(X)+1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 12) : **Dans un premier temps nous allons explorer le domaine de variation de $\\mu_B$ et $h$. Compléter le code ci-dessous afin de tracer les iso-valeurs de la fonction $(\\mu_B,h)\\rightarrow P_f^{FORM}$. Interpréter le résultat obtenu.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "mu_B_dis = np.linspace(0.5,1.1,n)\n",
    "h_dis = np.linspace(0.07,0.11,n)\n",
    "P_f_FORM_dis = []\n",
    "for mu_B in mu_B_dis:\n",
    "    for h in h_dis:\n",
    "        X=[mu_B,h]\n",
    "        P_f_FORM_dis.append(#A compléter)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_f_FORM_dis = np.array(P_f_FORM_dis)\n",
    "P_f_FORM_dis = P_f_FORM_dis.reshape((n,n)).T\n",
    "P_f_FORM_log = np.log(P_f_FORM_dis)\n",
    "X1,X2 = np.meshgrid(mu_B_dis,h_dis)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r'$\\mu_B$',fontsize = 40)\n",
    "ax.set_ylabel (r'$h$',fontsize=40)\n",
    "ax.tick_params(labelsize=40)\n",
    "ax.contour(X1,X2,P_f_FORM_log,levels = 20,linewidths=5) \n",
    "cs = ax.contourf(X1,X2,P_f_FORM_log,levels = 20,cmap=\"RdBu_r\")\n",
    "fig.colorbar(cs, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant résoudre le problème à l'aide de l'algorithme d'optimisation SLSQP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 13) : **Compléter le code ci-dessous afin de réaliser l'optimisation </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_fiab = {'type':'ineq','fun':#A compléter}\n",
    "X_0  = [1.0,0.1]\n",
    "bds = [[0.5,1.1],[0.07,0.11]]\n",
    "res_opt_masse = opt.minimize(f_obj_opt,X_0,method = 'SLSQP', constraints = cont_fiab, bounds = bds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"la masse optimisée est : \",res_opt_masse)\n",
    "print (\"la probabilité de défaillance en ce point est estimée à : \",-contrainte_fiab(res_opt_masse['x'])+1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4)  Monte-Carlo\n",
    "\n",
    "On se replacera au point initial $b = 1$ $h = 0.1$ (n'oubliez pas d'executer à nouveau la definition de la fonction G, la contruction des lois et des transformations iso-probabilistes pour ce point). On souhaite utiliser la méthode de Monte-Carlo pour vérifier l'approximation obtenue par la méthode FORM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 14) : **Completer le code suivant afin d'implémenter la méthode de Monte Carlo sur cet exemple. Que pouvez-vous dire de l'approximation obtenue par  la méthode FORM? Est-ce cohérent avec la forme de l'état limite au voisinage de $P^{\\star}$?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres géométriques\n",
    "L = 10.0 #longueur en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "##Définitions des paramètres\n",
    "n_elem = 50\n",
    "n_nodes = n_elem + 1\n",
    "Q_total = -3000.0\n",
    "mu = Q_total/(n_nodes)\n",
    "n_sim_max = 10**5\n",
    "cov_max = 0.1\n",
    "Indicatrice_Df = []\n",
    "Liste_Cov = []\n",
    "Liste_n_sim = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "t1 = t.time()\n",
    "while i<n_sim_max and cov>cov_max:\n",
    "    #Echantillon\n",
    "    E = np.array(#A compléter)\n",
    "    b = np.array(#A compléter)\n",
    "    X = np.array([E,b])\n",
    "    g = G(X)\n",
    "    if g>#A compléter:\n",
    "        Indicatrice_Df.append(#A compléter)\n",
    "    else:\n",
    "        Indicatrice_Df.append(#A compléter)\n",
    "    Pf = np.array(Indicatrice_Df).mean()    \n",
    "    if np.equal(np.mod(i/100.0, 1), 0):\n",
    "        cov = np.sqrt((1.0-Pf)/((i+1)*Pf))\n",
    "        Liste_Cov.append(cov)\n",
    "        Liste_n_sim.append(i+1)\n",
    "    i = i+1    \n",
    "t2 = t.time()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(Liste_n_sim,Liste_Cov,'ro')\n",
    "ax.set_ylabel('cov')\n",
    "ax.set_xlabel(r'$n_{sim}$')\n",
    "\n",
    "#Intervalle de confiance à 95%\n",
    "#Loi de student à n_sim-1 ddl\n",
    "n_sim = len(Indicatrice_Df)\n",
    "Var = 1.0/n_sim*Pf*(1.0-Pf)\n",
    "Stu = ot.Student(n_sim-1)\n",
    "alpha = 0.05\n",
    "q_t = Stu.computeQuantile(1.0-alpha/2.0)\n",
    "Pf_sup = Pf+q_t*np.sqrt(Var)\n",
    "Pf_inf = Pf-q_t*np.sqrt(Var)\n",
    "print (\"n_sim=\", n_sim)\n",
    "print (\"Pf=\", Pf)\n",
    "print (\"Pf_sup=\", Pf_sup)\n",
    "print (\"Pf_inf\", Pf_inf)\n",
    "print (\"L'analyse a duré, \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Tirage d'importance, approche FORM\n",
    "\n",
    "Nous allons à présent estimer la probabilité de défaillance par importance sampling. On rappelle que l'estimateur de $P_f$ par importance sampling est :\n",
    "$$\n",
    "\\hat{P}_{f_{is}} = \\frac{1}{n_{sim}} \\sum_{k= 1}^{n_{sim}} \\frac{\\mathbf{I}_{G(Y^{(k)})\\leq0}(Y^{(k)})f_X(Y^{(k)})}{f_Y(Y^{(k)})}\n",
    "$$\n",
    "\n",
    "et l'estimation de sa variance est :\n",
    "$$\n",
    "\\hat{\\sigma}_{\\hat{P_{f_{is}}}}^2 = \\frac{1}{n_{sim}^2}\\sum_{k=1}^{n_{sim}} \\left(  \\frac{\\mathbf{I}_{G(Y^{(k)})\\leq0}(Y^{(k)})f_X(Y^{(k)})}{f_Y(Y^{(k)})}- \\hat{P}_{f_{is}}\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 15) : **Mettre en oeuvre, dans l'espace normale standard,la méthode de Monte-Carlo et la méthode de tirage d'importance. Pour le tirage d'importance on utilisera pour densité auxiliaire une loi normale centrée sur le point $P^\\star$. Comparer les 2 approches et conclure. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graine du générateur de nombre aléatoire\n",
    "np.random.seed(seed=0)\n",
    "#Paramètres géométriques\n",
    "L = 10.0 #longueur en métre\n",
    "h = 0.1 #hauteur de la section en métre\n",
    "##Définitions des paramètres\n",
    "n_elem = 50\n",
    "n_nodes = n_elem + 1\n",
    "Q_total = -3000.0\n",
    "mu = Q_total/(n_nodes)\n",
    "#Monte Carlo dans l'espace normal standard\n",
    "#Loi normale centrée réduite\n",
    "N = ot.Normal()\n",
    "n_sim_max = 10**5\n",
    "cov_max = 0.1\n",
    "Indicatrice_Df = []\n",
    "Liste_Cov = []\n",
    "Liste_n_sim = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "t1 = t.time()\n",
    "#############ANALYSE MC##########\n",
    "#A compléter\n",
    "t2 = t.time()\n",
    "#Importance sampling\n",
    "#loi normale centrée réduite en 2D\n",
    "N_2 = ot.Normal(2)\n",
    "#loi auxiliaire\n",
    "N_IS =  ot.Normal(ot.Point(u_star),ot.CorrelationMatrix(2))\n",
    "n_sim_max = 10**4\n",
    "cov_max = 0.1\n",
    "Indicatrice_IS = []\n",
    "Indicatrice = []\n",
    "Liste_Cov_IS = []\n",
    "Liste_n_sim_IS = []\n",
    "Liste_w_i = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "t3 = t.time()\n",
    "############ANALYSE IC########\n",
    "#A compléter\n",
    "t4 = t.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(Liste_n_sim_IS,Liste_Cov_IS,'ro', label = 'IS')\n",
    "ax.plot(Liste_n_sim,Liste_Cov, 'bo', label='MC')\n",
    "ax.set_ylabel('cov')\n",
    "ax.set_xlabel(r'$n_{sim}$')\n",
    "ax.legend()\n",
    "#IMPORTANCE SAMPLING\n",
    "#Intervalle de confiance à 95%\n",
    "#Loi de student à n_sim-1 ddl\n",
    "n_sim = len(Indicatrice_IS)\n",
    "Var = sigma_2\n",
    "Stu = ot.Student(n_sim-1)\n",
    "alpha = 0.05\n",
    "q_t = Stu.computeQuantile(1.0-alpha/2.0)\n",
    "Pf_sup = Pf_IS+q_t*np.sqrt(Var)\n",
    "Pf_inf = Pf_IS-q_t*np.sqrt(Var)\n",
    "print(\"###########################\")\n",
    "print(\"IMPORTANCE SAMPLING\")\n",
    "print(\"n_sim=\", n_sim)\n",
    "print(\"Pf=\", Pf_IS)\n",
    "print(\"Pf_sup=\", Pf_sup)\n",
    "print(\"Pf_inf\", Pf_inf)\n",
    "print(\"L'analyse a duré, \", t4-t3)\n",
    "#MONTE CARLO\n",
    "#Intervalle de confiance à 95%\n",
    "#Loi de student à n_sim-1 ddl\n",
    "n_sim = len(Indicatrice_Df)\n",
    "Var = 1.0/n_sim*Pf*(1.0-Pf)\n",
    "Stu = stat.t(n_sim-1)\n",
    "alpha = 0.05\n",
    "q_t = Stu.ppf(1.0-alpha/2.0)\n",
    "Pf_sup = Pf+q_t*np.sqrt(Var)\n",
    "Pf_inf = Pf-q_t*np.sqrt(Var)\n",
    "print(\"###########################\")\n",
    "print(\"Monte Carlo\")\n",
    "print(\"n_sim=\", n_sim)\n",
    "print(\"Pf=\", Pf)\n",
    "print(\"Pf_sup=\", Pf_sup)\n",
    "print(\"Pf_inf\", Pf_inf)\n",
    "print(\"L'analyse a duré, \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## BONUS : Importance sampling non parametrique (NIS)\n",
    "Nous venons de voir que le tirage d'importance permet de réduire considérablement le temps de calcul de la méthode de Monte-Carlo. Toutefois pour la construction de la densité auxiliaire nous nous sommes appuyés sur l'analyse FORM qui suppose qu'il n'y a qu'un seul point de conception. \n",
    "\n",
    "On propose à présent d'étudier la fonction suivante de dimension 2 ayant 4 zones de défaillance dans l'espace normal standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    k = 6.0\n",
    "    Y1 = 3.0 + 0.1*(x[0]-x[1])**2-((x[0]+x[1])/np.sqrt(2.0))\n",
    "    Y2 = 3.0 + 0.1*(x[0]-x[1])**2+((x[0]+x[1])/np.sqrt(2.0))\n",
    "    Y3 = (x[0]-x[1])+k/np.sqrt(2.0)\n",
    "    Y4 = (x[1]-x[0])+k/np.sqrt(2.0)\n",
    "    return min(Y1,Y2,Y3,Y4)\n",
    "X = np.linspace(-8.0,8.0,300)\n",
    "res_tot = []\n",
    "for x1 in X:\n",
    "    res = []\n",
    "    for x2 in X:\n",
    "        x = np.array([x1,x2])\n",
    "        res.append(g(x))\n",
    "    res_tot.append(res)        \n",
    "\n",
    "res_tot = np.array(res_tot)\n",
    "X1,X2 = np.meshgrid(X,X)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r'$u_1$',fontsize = 40)\n",
    "ax.set_ylabel (r'$u_2$',fontsize=40)\n",
    "ax.tick_params(labelsize=40)\n",
    "ax.contour(X1,X2,res_tot,levels = np.array([0.0]),colors = 'k',linewidths=5) \n",
    "cs = ax.contourf(X1,X2,res_tot)\n",
    "fig.colorbar(cs, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 16) : **Mettre en oeuvre, dans l'espace normale standard,la méthode de Monte-Carlo. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graine du générateur de nombre aléatoire\n",
    "np.random.seed(seed=1)\n",
    "#Monte Carlo dans l'espace normal standard\n",
    "#Loi normale centrée réduite\n",
    "N = ot.Normal()\n",
    "n_sim_max = 10**5\n",
    "cov_max = 0.1\n",
    "Indicatrice_Df = []\n",
    "Liste_Cov = []\n",
    "Liste_n_sim = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "t1 = t.time()\n",
    "#A compléter   \n",
    "t2 = t.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (i)\n",
    "print (cov)\n",
    "n_sim = len(Indicatrice_Df)\n",
    "Var = 1.0/n_sim*Pf*(1.0-Pf)\n",
    "Stu = stat.t(n_sim-1)\n",
    "alpha = 0.05\n",
    "q_t = Stu.ppf(1.0-alpha/2.0)\n",
    "Pf_sup = Pf+q_t*np.sqrt(Var)\n",
    "Pf_inf = Pf-q_t*np.sqrt(Var)\n",
    "print(\"###########################\")\n",
    "print(\"Monte Carlo\")\n",
    "print(\"n_sim=\", n_sim)\n",
    "print(\"Pf=\", Pf)\n",
    "print(\"Pf_sup=\", Pf_sup)\n",
    "print(\"Pf_inf\", Pf_inf)\n",
    "print(\"L'analyse a duré, \", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 17) : **A partir d'un echantillon de taille $n$, nous allons chercher à construire une densité auxillaire qui se rapproche de la densité optimale. Pour cela nous utiliserons un estimateur non paramétrique à noyau (voir https://openturns.github.io/openturns/latest/user_manual/_generated/openturns.KernelSmoothing.html?highlight=kernelsmoothing et https://openturns.github.io/openturns/latest/auto_data_analysis/distribution_fitting/plot_estimate_non_parametric_distribution.html?highlight=kernelsmoothing ) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation de l'échantillon de taille \n",
    "n = 5000\n",
    "#graine du générateur de nombre aléatoire\n",
    "np.random.seed(seed=1)\n",
    "#Loi normale centrée réduite\n",
    "N = ot.Normal()\n",
    "n_sim_max = n\n",
    "Indicatrice_Df = []\n",
    "Liste_Cov = []\n",
    "Liste_n_sim = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "Liste_U = np.zeros((n,2))\n",
    "while i<n_sim_max:\n",
    "    #Echantillon dans l'espace normal standard\n",
    "    U_1 = np.array(N.getRealization())\n",
    "    U_2 = np.array(N.getRealization())\n",
    "    U = np.array([U_1,U_2])\n",
    "    Liste_U[i,0] = U_1\n",
    "    Liste_U[i,1] = U_2\n",
    "    if g(U)>0.0:\n",
    "        Indicatrice_Df.append(0)\n",
    "    else:\n",
    "        Indicatrice_Df.append(1)\n",
    "    Pf = np.array(Indicatrice_Df).mean()\n",
    "    i = i+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On conserve uniquement les échantillons défaillants\n",
    "ind = np.array(Indicatrice_Df)==#A compléter\n",
    "sample_def = Liste_U[#A compléter]\n",
    "print(sample_def.shape)\n",
    "#figure des échantillons défaillant\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r'$u_1$',fontsize = 40)\n",
    "ax.set_ylabel (r'$u_2$',fontsize=40)\n",
    "ax.tick_params(labelsize=40)\n",
    "ax.contour(X1,X2,res_tot,levels = np.array([0.0]),colors = 'k',linewidths=5) \n",
    "cs = ax.contourf(X1,X2,res_tot)\n",
    "ax.plot(Liste_U[:,0],Liste_U[:,1],'b+',markersize=20,label = 'echantillons')\n",
    "ax.plot(sample_def[:,0],sample_def[:,1],'r.',markersize=20,label = 'echantillons defaillants')\n",
    "fig.legend(loc=0)\n",
    "fig.colorbar(cs, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constructions de la densité non paramétrique\n",
    "kernel = ot.KernelSmoothing()\n",
    "pdf_estimated = kernel.build(#A compléter)\n",
    "#graph de la pdf estimée \n",
    "PDF = []\n",
    "for x1 in X:\n",
    "    pdf = []\n",
    "    for x2 in X:\n",
    "        x = np.array([x1,x2])\n",
    "        pdf.append(pdf_estimated.computePDF(x))\n",
    "    PDF.append(pdf)        \n",
    "PDF = np.array(PDF)\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r'$u_1$',fontsize = 40)\n",
    "ax.set_ylabel (r'$u_2$',fontsize=40)\n",
    "ax.tick_params(labelsize=40)\n",
    "ax.contour(X1,X2,res_tot,levels = np.array([0.0]),colors = 'k',linewidths=5) \n",
    "ax.contour(X1,X2,PDF,levels=20)\n",
    "ax.contourf(X1,X2,PDF,levels=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p class=\"bg-primary\" style=\"padding:1em\">** Question 18) : ** Compléter le code suivant afin d'utilser la densité auxiliaire créée pour le tirage d'importance.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_2 = ot.Normal(2)\n",
    "N_IS =  pdf_estimated\n",
    "n_sim_max = 10**4\n",
    "cov_max = 0.1\n",
    "Indicatrice_IS = []\n",
    "Indicatrice = []\n",
    "Liste_Cov_IS = []\n",
    "Liste_n_sim_IS = []\n",
    "Liste_w_i = []\n",
    "i = 0\n",
    "cov = 1.0\n",
    "t3 = t.time()\n",
    "#A compléter  \n",
    "t4 = t.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTANCE SAMPLING\n",
    "#Intervalle de confiance à 95%\n",
    "#Loi de student à n_sim-1 ddl\n",
    "n_sim = len(Indicatrice_IS)\n",
    "Var = sigma_2\n",
    "Stu = ot.Student(n_sim-1)\n",
    "alpha = 0.05\n",
    "q_t = Stu.computeQuantile(1.0-alpha/2.0)\n",
    "Pf_sup = Pf_IS+q_t*np.sqrt(Var)\n",
    "Pf_inf = Pf_IS-q_t*np.sqrt(Var)\n",
    "print(\"###########################\")\n",
    "print(\"IMPORTANCE SAMPLING\")\n",
    "print(\"n_sim=\", n_sim)\n",
    "print(\"Pf=\", Pf_IS)\n",
    "print(\"Pf_sup=\", Pf_sup)\n",
    "print(\"Pf_inf\", Pf_inf)\n",
    "print(\"L'analyse a duré, \", t4-t3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
